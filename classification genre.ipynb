{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torchvision import transforms as T\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "import random\n",
    "import tarfile\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/data/wikiart/wikiart_Painting100k/MultitaskPainting100k_Dataset_groundtruth/groundtruth_multiloss_train_header.csv')\n",
    "valid_df = pd.read_csv('/data/wikiart/wikiart_Painting100k/MultitaskPainting100k_Dataset_groundtruth/groundtruth_multiloss_test_header.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['img_path'] = train_df.apply(lambda x: join('/data/wikiart/wikiart_Painting100k/images_256minside',x.filename),1)\n",
    "valid_df['img_path'] = valid_df.apply(lambda x: join('/data/wikiart/wikiart_Painting100k/images_256minside',x.filename),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict_genre = {}\n",
    "for i, genre in enumerate(np.sort(train_df['genre'].unique())):\n",
    "    train_df.loc[train_df['genre']==genre, 'class_genre'] = i\n",
    "    valid_df.loc[valid_df['genre']==genre, 'class_genre'] = i\n",
    "    class_dict_genre.update({i:genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.RandomResizedCrop(size=224, scale=(0.3,1), ratio=(1,1)),\n",
    "    T.RandomHorizontalFlip(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = train_df.iloc[3]\n",
    "tr(Image.open(row.img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "        T.Resize(256), \n",
    "        T.RandomResizedCrop(size=224, scale=(0.3,1), ratio=(1, 1)), #size 384. scale specifies the lower and upper bounds for the random area of the crop\n",
    "        T.RandomHorizontalFlip(p=0.5), #p probability of the image being flipped\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                    std=[0.229, 0.224, 0.225])])\n",
    "valid_transforms = T.Compose([\n",
    "        T.Resize(224), \n",
    "        T.CenterCrop(224), \n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                    std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        im = Image.open(row.img_path).convert('RGB')\n",
    "        return self.transform(im), torch.LongTensor([float(row.class_genre)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "\n",
    "train_dataset = ImageDataset(train_df.reset_index(drop=True), train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False, num_workers=6)\n",
    "\n",
    "\n",
    "valid_dataset = ImageDataset(valid_df.reset_index(drop=True), valid_transforms)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, pin_memory=False, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    npimg = image.numpy().transpose(1, 2, 0)\n",
    "    npimg = npimg/(npimg.max()-npimg.min())+0.5\n",
    "    plt.imshow(npimg)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "img, target = dataiter.next()\n",
    "#concatenate = torch.cat((anchor, positive, negative), 0)\n",
    "#imshow(torchvision.utils.make_grid(concatenate, nrow = batch_size))\n",
    "imshow(torchvision.utils.make_grid(img, nrow = batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnest = encoding.models.get_model('ResNeSt50', pretrained=True)\n",
    "resnest.fc = nn.Identity()\n",
    "\n",
    "condition = torch.LongTensor([0]).to(device)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, base_model, condition):\n",
    "        super(Net, self).__init__()\n",
    "        self.base=base_model\n",
    "        self.fc = nn.Sequential( \n",
    "            nn.PReLU(),\n",
    "            nn.Linear(2048, 41)\n",
    "            )\n",
    "        self.masks = torch.nn.Embedding(1, 2048)\n",
    "        mask_array = np.zeros([1, 2048])\n",
    "        mask_array.fill(0.1)\n",
    "        mask_array[0, 0:1024] = 1\n",
    "        self.masks.weight = torch.nn.Parameter(torch.Tensor(mask_array), requires_grad=True)\n",
    "        self.condition = condition\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embed = self.base(x)\n",
    "        self.mask = self.masks(self.condition)\n",
    "        self.mask = torch.nn.functional.relu(self.mask)\n",
    "        masked_embed = embed * self.mask\n",
    "        \n",
    "        out = self.fc(masked_embed)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(resnest, condition).to(device)\n",
    "\n",
    "lr = 1.e-3\n",
    "#optimizer = torch.optim.SGD([{'params':model.base.parameters(), 'lr':1.e-6},{'params':model.fc.parameters(),   'lr':lr}], lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "optimizer = torch.optim.Adam([{'params':model.base.parameters(), 'lr':1.e-5}, {'params':model.fc.parameters(),   'lr':lr}], lr=lr, weight_decay=1.e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda epoch: 0.98)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, device, train_loader, optimizer, epoch):\n",
    "    t = Timer(); t.start()\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    loss_list, pred_list, real_list = [], [], []\n",
    "    \n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(train_loader):\n",
    "\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out  = model(img)\n",
    "        loss = loss_func(out, label.squeeze(1))\n",
    "        \n",
    "        values, indices = torch.max(softmax(out), dim=1)\n",
    "        pred_list.append(indices.flatten().detach().cpu().numpy())\n",
    "        real_list.append(label.flatten().detach().cpu().numpy())\n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        real = np.concatenate(real_list, 0).flatten()\n",
    "        pred = np.concatenate(pred_list, 0).flatten()\n",
    "        acc  = accuracy_score(real, pred)\n",
    "        \n",
    "        template = \"Train--> [{}:{}] Iteration {} ({:3.1f}%): Loss = {:.4f} | Accuracy = {:.3f}\\r\"\n",
    "        loss_arr = np.array(loss_list)\n",
    "        percentage = 100*batch_idx/len(train_loader)\n",
    "        stop_time = t.stop()\n",
    "        print(template.format(round(stop_time/60), round(stop_time)%60, batch_idx, percentage, np.mean(loss_arr), acc), end='')\n",
    "        if percentage == 100: break            \n",
    "    stop_time = t.stop()    \n",
    "    print(template.format(round(stop_time/60), round(stop_time)%60, batch_idx, percentage, np.mean(loss_arr), acc))\n",
    "    return model, np.mean(loss_arr), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, loss_func, device, loader, epoch):\n",
    "    t = Timer(); t.start()\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    loss_list, pred_list, real_list = [], [], []\n",
    "\n",
    "    for batch_idx, (img, label) in enumerate(loader):\n",
    "        \n",
    "        img, label = img.to(device), label.to(device)\n",
    "        \n",
    "        out = model(img)\n",
    "        loss = loss_func(out, label.squeeze(1))\n",
    "       \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "        values, indices = torch.max(softmax(out), dim=1)\n",
    "        pred_list.append(indices.flatten().detach().cpu().numpy())\n",
    "        real_list.append(label.flatten().detach().cpu().numpy())\n",
    "\n",
    "        percentage = batch_idx/len(loader)\n",
    "        print('Computing Validation ({:.1%})\\r'.format(percentage), end='')\n",
    "        if percentage == 1: break\n",
    "\n",
    "    real = np.concatenate(real_list, 0).flatten()\n",
    "    pred = np.concatenate(pred_list, 0).flatten()\n",
    "\n",
    "    acc = accuracy_score(real, pred)\n",
    "\n",
    "    template = \"Valid--> [{}:{}] Iteration {}: Loss = {:.4f} | Accuracy = {:.3f}\"\n",
    "    loss_arr = np.array(loss_list)\n",
    "    stop_time = t.stop()\n",
    "    print(template.format(round(stop_time/60), round(stop_time)%60, batch_idx, np.mean(loss_arr), acc),)\n",
    "    return np.mean(loss_arr), acc, np.concatenate(pred_list, 0), np.concatenate(real_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_loss_fig(loss_train, loss_valid, accuracy_train, accuracy_valid, epoch):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,4))\n",
    "    ax1.plot([i for i in range(len(loss_train))], loss_train, label='train_loss')\n",
    "    ax1.plot([i for i in range(len(loss_valid))],  loss_valid,  label='valid_loss')\n",
    "    ax1.set(xlabel='epoch', ylabel='loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot([i for i in range(len(accuracy_train))], accuracy_train, label='train_accuracy')\n",
    "    ax2.plot([i for i in range(len(accuracy_valid))],  accuracy_valid,  label='valid_accuracy')\n",
    "    ax2.set(xlabel='epoch', ylabel='accuracy')\n",
    "    ax2.legend()\n",
    "    fig.suptitle(f'EPOCH {epoch}', fontsize=16)\n",
    "    plt.close(fig)\n",
    "    fig.savefig(os.path.join('.', \"loss_plot_genre_resnest.jpg\"), pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "    def start(self):\n",
    "        self._start_time = time.perf_counter()\n",
    "    def stop(self):\n",
    "        elapsed_time = time.perf_counter() - self._start_time\n",
    "        return round(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = [], [], [], []\n",
    "best_criterion = 2\n",
    "\n",
    "for epoch in range(50):\n",
    "    \n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    \n",
    "    model, train_loss, acc_train= train(model, criterion, device, train_loader, optimizer, epoch)\n",
    "    \n",
    "    valid_loss, acc_valid, pred, real = valid(model, criterion, device, valid_loader, epoch) \n",
    "    #scheduler.step(valid_loss)\n",
    "    if valid_loss < best_criterion:\n",
    "        \n",
    "        best_criterion = valid_loss\n",
    "        torch.save(model, './resnest_genre_model.pt')\n",
    "        print('------------------------------------------------------------------ Best Model ------------------------------------------------------------------')\n",
    "                                     \n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(acc_train)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_acc_list.append(acc_valid)\n",
    "    save_loss_fig(train_loss_list, valid_loss_list, train_acc_list, valid_acc_list, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('/data/Notebook/CNN/resnest_genre_model.pt', map_location=device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabels = []\n",
    "predictions = []\n",
    "outs = []\n",
    "model.eval()\n",
    "\n",
    "for data, target in valid_loader:\n",
    "    for label in target.data.numpy():\n",
    "        truelabels.append(label)\n",
    "    out = model(data.to(device))\n",
    "    outs.append(out.detach().cpu().numpy())\n",
    "    for prediction in out.data.argmax(1):\n",
    "        predictions.append(prediction.detach().cpu().numpy().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_genre_name = []\n",
    "list_genre_lab = []\n",
    "for i, name in class_dict_genre.items():\n",
    "    list_genre_name.append(name)\n",
    "    list_genre_lab.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truelabels, predictions, labels = list_genre_lab , normalize='true')\n",
    "cm.diagonal()/cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_marks = np.arange(len(list_genre_name))\n",
    "df_cm = pd.DataFrame(cm, index = list_genre_name, columns = list_genre_name)\n",
    "plt.figure(figsize = (30,30))\n",
    "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Reds, fmt='.2f')\n",
    "plt.xlabel(\"Predicted\", fontsize = 10)\n",
    "plt.ylabel(\"True\", fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(truelabels, predictions, labels=list_genre_lab, target_names = list_genre_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(\"precision: \", precision_score(truelabels, predictions, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(test_df.filename.iloc[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = valid_df.sample(1).iloc[0]\n",
    "print(f'Actual genre: {row.genre}')\n",
    "im = Image.open(row.img_path).convert('RGB')\n",
    "X = []\n",
    "#out = model(test_transforms(im).unsqueeze(0).to(device))\n",
    "#X.append(out.detach().cpu().numpy())\n",
    "#pred = clf.predict(np.concatenate(X))\n",
    "pred = model(valid_transforms(im).unsqueeze(0).to(device)).argmax(1)\n",
    "#pred_probs = torch.nn.functional.softmax(pred_tensor, dim=1).data.numpy()\n",
    "print(f'Predi. genre: {class_dict_genre[pred.item()]}')\n",
    "T.Resize(250)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saliency map https://github.com/sunnynevarekar/pytorch-saliency-maps/blob/master/Saliency_maps_in_pytorch.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
